{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook to set up a RAG application for posing questions to a set of Word documents in a local folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Ollama model and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What do you call a guy who's always telling jokes but never gets laughed at?\\n\\nA joke-a-day man!\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code for accessing Ollama and posing questions\n",
    "# Test wether it works to invoke a model and pose a question\n",
    "\n",
    "MODEL = \"gemma:2b\"\n",
    "# MODEL = \"mistral\"\n",
    "# MODEL = \"llama2\"\n",
    "\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "model = Ollama(model=MODEL)\n",
    "embeddings = OllamaEmbeddings(model=MODEL)\n",
    "\n",
    "# Actual method to invoke a model and ask a question:\n",
    "#model.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Documents to apply the RAG to.\n",
    "Get a list of paths of docx documents I want to load into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path = os.getenv(\"DOCUMENTS_PATH\")\n",
    "\n",
    "# Retrieve the path names of files in the specified directory\n",
    "docx_file_paths = [os.path.join(data_path, file) for file in os.listdir(data_path)]\n",
    "docx_file_paths_cleaned = [item for item in docx_file_paths if item.endswith('.docx')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in files to apply RAG to\n",
    "Load the docx files into memory using langchain's Docx2txtLoader function. The load_and_split function then serves to chunk documents. \n",
    "\n",
    "For now it seems that it chuncks automatically on page, although I want to see if I can reduce chunck size, as this is hopefully better for creating the embeddings. I'm running into serious performance issues on my MBA when using embeddings on chunk page sizes. Pehaps smaller chunks offer better performance (?!?) IDK...\n",
    "\n",
    "It seems that the nltk library offers helpful functionality with tokenization. Perhaps I can get chunck size down to sentences or "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document is split into 2 chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "loaded_texts = [Docx2txtLoader(path) for path in docx_file_paths_cleaned]\n",
    "\n",
    "test_pages = loaded_texts[8].load_and_split()\n",
    "\n",
    "\n",
    "# To find out the number of chunks\n",
    "number_of_chunks = len(test_pages)\n",
    "print(f\"The document is split into {number_of_chunks} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embeddings\n",
    "For now the vector store is in memory, with the use of the DocArrayInMemorySearch method from the langchain_community library, but the goal is to write it to disk to probably free up RAM (check chromaDB?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Initiatief: BRN-06-01a Corrigeren en aanvullen gerelateerdengegevens\\n\\nFase 1: Binnen gemeentelijk\\n\\n\\nVoordat een initiatief voor impactanalyse aan RvIG kan worden aangeboden moet voldoende duidelijk zijn wat het probleem is en de gewenste ‘business’-oplossing. Ook moet gespecificeerd zijn wat de acceptatiecriteria zijn die worden gesteld aan de oplossingsrichting(en) voor implementatie. \\n\\nDeze template beschrijft de inhoud van een initiatiefbeschrijving om “ready” te zijn voor impactanalyse.\\n\\nInitiatieven worden beschreven door het Realisatieteam en aangeboden aan het portfolio-overleg\\n\\n\\n\\nOnderwerp \\n\\nCorrigeren en aanvullen van gerelateerdengegevens op de persoonslijst\\n\\nSamenvatting van het initiatief\\n\\nTijdens de ontwikkeling van Operatie BRP is gebleken dat de gerelateerdengegevens op de persoonslijsten in de BRP hiaten en fouten bevatten. In totaal ging het om miljoenen sets gerelateerdengegevens. Dit initiatief richt zich op inconsistenties op PL’en die binnen één gemeentelijke BRP bevinden (binnen gemeentelijk) Hiertoe wordt een systematiek voorgesteld waarbij vanuit GBA-V wijzigingsvoorstellen aan de gemeenten worden gestuurd die (geautomatiseerd) kunnen worden verwerkt. De overblijvende gevallen die niet automatisch kunnen worden verwerkt, worden door de gemeenten via de Kwaliteitsmonitor opgelost (destijds was de schatting dat het om circa 400.000 handmatige correcties zou gaan).\\n\\nGevraagde impactanalyse\\n\\nGevraagd wordt om te onderzoeken of (1) de werkwijze van Operatie BRP voor het selecteren van ontbrekende en hinkende relaties voor dit initiatief herbruikbaar is in de context van GBA-V zo nee, wat een alternatieve werkwijze kan zijn, (2) of de systematiek van wijzigingsvoorstellen (Tb-berichten) kan werken en zo nee, wat een alternatief kan zijn, en (3) welk deel handmatig gewijzigd of gecorrigeerd moet worden en wat daarvoor de geëigende methode is.\\n\\nDeze fase 1 richt zich op inconsistenties op PL’en die binnen één gemeentelijke BRP bevinden (binnen gemeentelijk).\\n\\nGewenste datum realisatie\\n\\n1-1-2024 (staat op MVP-lijst 2023)\\n\\nAanleiding/ probleemstelling \\n\\nEen van de doelstellingen van Operatie BRP was om te komen tot een centrale bijhouding van de BRP-gegevens. Voor die centrale bijhouding was een nieuw datamodel ontwikkeld, waarbinnen de zogenaamde ‘multirealiteit’ geen plek meer had. Met multirealiteit werd gedoeld op de situatie dat de relaties tussen personen in de BRP niet genormaliseerd opgeslagen zijn, waardoor een relatie tussen twee personen niet altijd eenduidig is; zo kan het voorkomen dat vanuit persoonslijst A er een huwelijksrelatie is met persoonslijst B, terwijl die huwelijksrelatie vanuit persoonslijst B niet voorkomt. \\n\\nEen van de aansluitvoorwaarden voor de gemeenten was dat op moment van overdracht van de persoonslijsten naar de centrale voorziening, de gemeenten akkoord moesten geven op het geautomatiseerd aanvullen van de gerelateerdengegevens. De handmatige acties moesten van tevoren uitgevoerd zijn. Met het stopzetten van Operatie BRP is deze kwaliteitsslag gestopt.\\n\\nOp hoofdlijnen is een aantal hiaten en fouten geïnventariseerd, die ieder een eigen aanpak vergen:\\n\\nOntbrekende relaties\\nDit gaat vooral over kindgegevens die niet op de persoonskaart stonden bij de invoering van de GBA in 1994.\\n\\nMultirealiteit (ook genoemd “hinkende relaties”)\\nRelaties die op de ene persoonslijst wel verwerkt zijn, maar op de andere niet, bijvoorbeeld een huwelijksontbinding.\\nLet op: er bestaan ook bedoelde vormen van multirealiteit, bijvoorbeeld als gevolg van een geslachtsverandering die op verzoek van een gerelateerde niet op diens persoonslijst is verwerkt. Deze situaties moeten niet gecorrigeerd worden.\\n\\nUitzoekgevallen (“Baseline 2 controles” onder Operatie BRP)\\nSituaties waarbij niet geautomatiseerd vastgesteld kan worden wat er aan de hand is. Bijvoorbeeld vanwege verschillen in schrijfwijze of deels ontbrekende of onbekende gegevens.\\n\\nWaarde, beoogde baten', metadata={'source': '/Users/home/Documents/Entrador/RvIG/Algemeen/Initiatieven analyse/initiatieven/BRN-06-01a Initiatief-Corrigeren en aanvullen gerelateerdengegevens - fase1 binnen gemeentelijk v2.docx'}),\n",
       " Document(page_content='Waarde, beoogde baten\\n\\nAfnemers hebben op dit moment geen volledig zicht op de bestaande familierelaties tussen personen in de BRP. Dit leidt tot fouten in de interpretatie van die gegevens en als gevolg daarvan veel administratieve lasten. Het aanvullen en corrigeren van deze relaties is een belangrijke kwaliteitsverhogende maatregel. Daarnaast is het een voorwaarde om op termijn over te gaan op een genormaliseerde gegevensopslag.   \\n\\nNul-alternatief\\n\\nZonder dit initiatief blijft de kwaliteit van de familierelaties in de BRP op een te laag niveau, zeker voor de persoonslijsten die in 1994 geconverteerd zijn vanaf de persoonskaart. Deze situatie is ook een blokkade voor de toekomstige overstap naar een genormaliseerde (en mogelijk gecentraliseerde) gegevensopslag.\\n\\nAcceptatiecriteria voor implementatie-oplossingsrichting\\n\\nHet percentage vals-positieven (onterechte relatielegging) moet zo laag mogelijk zijn.\\n\\nDe afhandeling van de bijhoudingsvoorstellen moet door de gemeente geautomatiseerd uitgevoerd kunnen worden. Het aantal ontbrekende relaties loopt in de miljoen; dit is handmatig niet uitvoerbaar voor de gemeenten.\\n\\nAandachtspunten\\n\\nDe synchroniciteit tussen de BRP-bestanden van de gemeenten en GBA-V moet zo hoog mogelijk zijn om foute bijhoudingsvoorstellen als gevolg van asynchroniciteit te voorkomen.\\n\\n\\n\\nAandacht voor bedoelde situaties van multirealiteit die juist niet gecorrigeerd mogen worden (zie onder Aanleiding/probleemstelling).\\n\\nRelatie met andere onderwerpen\\n\\n\\n\\nRisico’s en maatregelen\\n\\n\\nRisico: Bezwaar bij gemeenten tegen de hoeveelheid handwerk.\\n\\nGevolg: De handmatige wijzigingen worden niet overal doorgevoerd waardoor het initiatief maar deels wordt uitgevoerd en niet alle baten worden bereikt.\\n\\nMaatregel: Monitoring op de afhandeling, eventueel aanbieden van ondersteuning aan de betreffende gemeente(n).\\n\\nRisico: Gemeenten willen de bijhoudingsberichten niet automatisch verwerken.\\n\\nGevolg: Handmatige afhandeling zal tot grote achterstanden leiden, en daardoor leiden tot een nieuwe multirealiteit omdat onduidelijk is welke relaties wel en niet tweezijdig gelegd zijn.\\n\\nMaatregel: Vanaf het begin werken aan draagvlak bij gemeenten voor dit initiatief. In overleg met ‘gewetensbezwaarden’. \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\n\\n2', metadata={'source': '/Users/home/Documents/Entrador/RvIG/Algemeen/Initiatieven analyse/initiatieven/BRN-06-01a Initiatief-Corrigeren en aanvullen gerelateerdengegevens - fase1 binnen gemeentelijk v2.docx'})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(test_pages, embedding = embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# test the application of the vector store \n",
    "retriever.invoke(\"Gewenste datum realisatie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Template\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Templates help "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt.format(context=\"Here is some context\", question=\"Here is a question\")\n",
    "\n",
    "# Inspect how the prompt will look like:\n",
    "print(prompt.format(context=\"Here is some context\", question=\"Here is a question\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#chain.invoke(\n",
    "#    {\n",
    "#\n",
    "#    \"question\": \"Geef de code van dit initiatief, deze heeft de vorm van AAA-11-11 \" \n",
    "#    }\n",
    "#)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
